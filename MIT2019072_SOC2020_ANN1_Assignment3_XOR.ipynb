{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron_XOR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQu4QjFkjUKA1+Evc02Oi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afzal786/Soft_Computing/blob/master/MIT2019072_SOC2020_ANN1_Assignment3_XOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLHh8w07Ok9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "53842b0e-0b72-401e-ab32-6b17ddb432d2"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# class Perceptron consist of all the functions for the perceptron algo to function\n",
        "class Perceptron(object):\n",
        "    #initializing the weights, learning rate, epochs\n",
        "    def __init__(self, input_size, lr=0.1, epochs=10000):\n",
        "        self.W = np.zeros(input_size+1)\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "    # here the activation function used is if W.x + b >= 0 return 1 else 0\n",
        "    def activation_fn(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "    \n",
        "    # This function predict the value of the particular dataset \n",
        "    def predict(self, x):\n",
        "        z = self.W.T.dot(x)\n",
        "        a = self.activation_fn(z)\n",
        "        return a\n",
        " \n",
        "    # This function runs the training of the network. \n",
        "    def fit(self, X, d):\n",
        "        for _ in range(self.epochs): #runs the epochs\n",
        "            for i in range(d.shape[0]): #runs through the number of data points in dataset\n",
        "                x = np.insert(X[i], 0, 1) #adding bias at the begining of the data points\n",
        "                y = self.predict(x) #predicting the value\n",
        "                e = d[i] - y #calculating the error\n",
        "                self.W = self.W + self.lr * e * x #modifying the weigths of the network."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q60aJh9IOo6Y",
        "colab_type": "code",
        "outputId": "9916d700-64f5-41c6-90b1-b7852104f12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#input set for AND && OR operation\n",
        "X = np.array([\n",
        "        [0, 0],\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "        [1, 1]\n",
        "])\n",
        "\n",
        "#input set for the NOT operation\n",
        "X_not = np.array([[0],[1]])\n",
        "\n",
        "# This section consist of y actual values of OR function, then initializing the perceptron to number of columns in dataset \n",
        "# and then running the perceptron algo\n",
        "y_or = np.array([0, 1, 1, 1])\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.fit(X, y_or)\n",
        "w_or = perceptron.W.reshape(1,3)\n",
        "\n",
        "#printing the weights obtained.\n",
        "print(\"Weight Obtained for OR : {}\".format(w_or))\n",
        "\n",
        "# This section consist of y actual values of AND function, then initializing the perceptron to number of columns in dataset \n",
        "# and then running the perceptron algo\n",
        "y_and = np.array([0, 0, 0, 1])\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.fit(X, y_and)\n",
        "w_and = perceptron.W.reshape(1,3)\n",
        "\n",
        "#printing the weights obtained.\n",
        "print(\"Weight Obtained for AND : {}\".format(w_and))\n",
        "\n",
        "# This section consist of y actual values of NOT function, then initializing the perceptron to number of columns in dataset \n",
        "# and then running the perceptron algo\n",
        "y_not = np.array([1, 0])\n",
        "perceptron = Perceptron(input_size=1)\n",
        "perceptron.fit(X_not, y_not)\n",
        "w_not = perceptron.W.reshape(1,2)\n",
        "\n",
        "#printing the weights obtained.\n",
        "print(\"Weight Obtained for NOT : {}\".format(w_not))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight Obtained for OR : [[-0.1  0.1  0.1]]\n",
            "Weight Obtained for AND : [[-0.2  0.2  0.1]]\n",
            "Weight Obtained for NOT : [[ 0.  -0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcO4jIpaoLPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting the predicted values.\n",
        "\n",
        "def get_output(X_new,w):\n",
        "  X_new = np.insert(X_new,0,1)\n",
        "\n",
        "  y_pred = X_new@w.T\n",
        "    \n",
        "  #print(y_pred)\n",
        "    \n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i] >= 0:\n",
        "      y_pred[i] = 1\n",
        "    else:\n",
        "      y_pred[i] = 0\n",
        "\n",
        "  y_pred = y_pred.reshape(len(y_pred),1)\n",
        "\n",
        "  return y_pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa-HhvSJsQOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multi-layer perceptron Algorithm for the XOR implementation \n",
        "#XOR(x1,x2) = AND(NOT(AND(x1,x2)),OR(x1,x2)) \n",
        "def XOR_net(x):\n",
        "    gate_1 = get_output(x,w_and)\n",
        "    gate_2 = get_output(gate_1,w_not)\n",
        "    gate_3 = get_output(x,w_or)\n",
        "    new_x = np.array([gate_2, gate_3])\n",
        "    output = get_output(new_x,w_and)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVu-Gr3yshDs",
        "colab_type": "code",
        "outputId": "c47058af-e1ea-44e2-9f77-73b6452e3efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y_output_xor = np.zeros(4).reshape(4,1)\n",
        "y_output_xor[0] = XOR_net(np.array([0,0]))\n",
        "y_output_xor[1] = XOR_net(np.array([0,1]))\n",
        "y_output_xor[2] = XOR_net(np.array([1,0]))\n",
        "y_output_xor[3] = XOR_net(np.array([1,1]))\n",
        "\n",
        "\n",
        "#printing the XOR- output\n",
        "print(y_output_xor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MgB1B5XgqcE",
        "colab_type": "code",
        "outputId": "aa813a08-d316-4a5a-8ca1-10905c24b2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(\"Output Predicted : \\n\")\n",
        "\n",
        "# Creating the dataset in the desired format.\n",
        "data1  = np.vstack((X.T,y_output_xor.T)).T\n",
        "\n",
        "# creating dataframe of the array in order to give it as input in seaborn plotting fucntion.\n",
        "dataframe1 = pd.DataFrame(data=data1, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\n",
        "\n",
        "\n",
        "print(dataframe1.head(5))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output Predicted : \n",
            "\n",
            "\n",
            "   1st_principal  2nd_principal  label\n",
            "0            0.0            0.0    0.0\n",
            "1            0.0            1.0    1.0\n",
            "2            1.0            0.0    1.0\n",
            "3            1.0            1.0    0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu12ZbBNfK4h",
        "colab_type": "code",
        "outputId": "121ea50d-3349-43ea-ae80-429db1a55ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "# Plotting the classification result for the OR operation .\n",
        "sns.FacetGrid(dataframe1, hue=\"label\", size=6).map(plt.scatter, '2nd_principal', '1st_principal').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/axisgrid.py:243: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAGoCAYAAADsEFQiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 483.875x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}